{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "cwd = Path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJL\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>likes_x</th>\n",
       "      <th>replies</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes_y</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>date</th>\n",
       "      <th>likes_log</th>\n",
       "      <th>views_log</th>\n",
       "      <th>dislikes_log</th>\n",
       "      <th>comment_log</th>\n",
       "      <th>category_name</th>\n",
       "      <th>like_rate</th>\n",
       "      <th>dislike_rate</th>\n",
       "      <th>comment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>Logan Paul it's yo big day ‼️‼️‼️</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...</td>\n",
       "      <td>Logan Paul Vlogs</td>\n",
       "      <td>24</td>\n",
       "      <td>logan paul vlog|logan paul|logan|paul|olympics...</td>\n",
       "      <td>4394029</td>\n",
       "      <td>320053</td>\n",
       "      <td>...</td>\n",
       "      <td>https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>12.676245</td>\n",
       "      <td>15.295757</td>\n",
       "      <td>8.688117</td>\n",
       "      <td>10.741730</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>7.283816</td>\n",
       "      <td>0.134979</td>\n",
       "      <td>1.052451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>Logan Paul it's yo big day ‼️‼️‼️</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...</td>\n",
       "      <td>Logan Paul Vlogs</td>\n",
       "      <td>24</td>\n",
       "      <td>logan paul vlog|logan paul|logan|paul|olympics...</td>\n",
       "      <td>5457497</td>\n",
       "      <td>349857</td>\n",
       "      <td>...</td>\n",
       "      <td>https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg</td>\n",
       "      <td>14.09</td>\n",
       "      <td>12.765283</td>\n",
       "      <td>15.512501</td>\n",
       "      <td>9.768813</td>\n",
       "      <td>10.868264</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>6.410576</td>\n",
       "      <td>0.320275</td>\n",
       "      <td>0.961668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>Logan Paul it's yo big day ‼️‼️‼️</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...</td>\n",
       "      <td>Logan Paul Vlogs</td>\n",
       "      <td>24</td>\n",
       "      <td>logan paul vlog|logan paul|logan|paul|olympics...</td>\n",
       "      <td>5854127</td>\n",
       "      <td>361422</td>\n",
       "      <td>...</td>\n",
       "      <td>https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg</td>\n",
       "      <td>15.09</td>\n",
       "      <td>12.797804</td>\n",
       "      <td>15.582658</td>\n",
       "      <td>9.999888</td>\n",
       "      <td>10.909107</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>6.173798</td>\n",
       "      <td>0.376196</td>\n",
       "      <td>0.933888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>Logan Paul it's yo big day ‼️‼️‼️</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...</td>\n",
       "      <td>Logan Paul Vlogs</td>\n",
       "      <td>24</td>\n",
       "      <td>logan paul vlog|logan paul|logan|paul|olympics...</td>\n",
       "      <td>5997736</td>\n",
       "      <td>366401</td>\n",
       "      <td>...</td>\n",
       "      <td>https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg</td>\n",
       "      <td>16.09</td>\n",
       "      <td>12.811486</td>\n",
       "      <td>15.606893</td>\n",
       "      <td>10.038281</td>\n",
       "      <td>10.587266</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>6.108988</td>\n",
       "      <td>0.381561</td>\n",
       "      <td>0.660683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>Logan Paul it's yo big day ‼️‼️‼️</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...</td>\n",
       "      <td>Logan Paul Vlogs</td>\n",
       "      <td>24</td>\n",
       "      <td>logan paul vlog|logan paul|logan|paul|olympics...</td>\n",
       "      <td>6109026</td>\n",
       "      <td>369963</td>\n",
       "      <td>...</td>\n",
       "      <td>https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg</td>\n",
       "      <td>17.09</td>\n",
       "      <td>12.821161</td>\n",
       "      <td>15.625278</td>\n",
       "      <td>10.052252</td>\n",
       "      <td>10.567489</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>6.056006</td>\n",
       "      <td>0.379881</td>\n",
       "      <td>0.635944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                       comment_text likes_x replies  \\\n",
       "0  XpVt6Z1Gjjo  Logan Paul it's yo big day ‼️‼️‼️       4       0   \n",
       "1  XpVt6Z1Gjjo  Logan Paul it's yo big day ‼️‼️‼️       4       0   \n",
       "2  XpVt6Z1Gjjo  Logan Paul it's yo big day ‼️‼️‼️       4       0   \n",
       "3  XpVt6Z1Gjjo  Logan Paul it's yo big day ‼️‼️‼️       4       0   \n",
       "4  XpVt6Z1Gjjo  Logan Paul it's yo big day ‼️‼️‼️       4       0   \n",
       "\n",
       "                                               title     channel_title  \\\n",
       "0  1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...  Logan Paul Vlogs   \n",
       "1  1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...  Logan Paul Vlogs   \n",
       "2  1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...  Logan Paul Vlogs   \n",
       "3  1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...  Logan Paul Vlogs   \n",
       "4  1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...  Logan Paul Vlogs   \n",
       "\n",
       "   category_id                                               tags    views  \\\n",
       "0           24  logan paul vlog|logan paul|logan|paul|olympics...  4394029   \n",
       "1           24  logan paul vlog|logan paul|logan|paul|olympics...  5457497   \n",
       "2           24  logan paul vlog|logan paul|logan|paul|olympics...  5854127   \n",
       "3           24  logan paul vlog|logan paul|logan|paul|olympics...  5997736   \n",
       "4           24  logan paul vlog|logan paul|logan|paul|olympics...  6109026   \n",
       "\n",
       "   likes_y  ...                                  thumbnail_link   date  \\\n",
       "0   320053  ...  https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg  13.09   \n",
       "1   349857  ...  https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg  14.09   \n",
       "2   361422  ...  https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg  15.09   \n",
       "3   366401  ...  https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg  16.09   \n",
       "4   369963  ...  https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg  17.09   \n",
       "\n",
       "   likes_log  views_log  dislikes_log  comment_log  category_name  like_rate  \\\n",
       "0  12.676245  15.295757      8.688117    10.741730  Entertainment   7.283816   \n",
       "1  12.765283  15.512501      9.768813    10.868264  Entertainment   6.410576   \n",
       "2  12.797804  15.582658      9.999888    10.909107  Entertainment   6.173798   \n",
       "3  12.811486  15.606893     10.038281    10.587266  Entertainment   6.108988   \n",
       "4  12.821161  15.625278     10.052252    10.567489  Entertainment   6.056006   \n",
       "\n",
       "  dislike_rate  comment_rate  \n",
       "0     0.134979      1.052451  \n",
       "1     0.320275      0.961668  \n",
       "2     0.376196      0.933888  \n",
       "3     0.381561      0.660683  \n",
       "4     0.379881      0.635944  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Read in Raw Data: Comments.csv'''\n",
    "\n",
    "comments_df= pd.read_csv(cwd/'output'/'comments.csv',error_bad_lines=False)\n",
    "videos_df=pd.read_csv(cwd/'output'/'videos.csv', error_bad_lines=False)\n",
    "comments_df=pd.merge(comments_df, videos_df, on='video_id',how='left')\n",
    "comments_df.drop_duplicates(inplace=True)\n",
    "\n",
    "comments_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Map category name into the dataframe'''\n",
    "\n",
    "with open(cwd/'data_scraper'/'kaggle'/'GB_category_id.json') as json_file:\n",
    "    gb_json = json.load(json_file)\n",
    "\n",
    "id_to_category = {}\n",
    "for i in gb_json['items']:\n",
    "    category = i['snippet']['title']\n",
    "    id = int(i['id'])\n",
    "    id_to_category[id] = category\n",
    "training_id = []\n",
    "for i in id_to_category:\n",
    "    training_id.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "comments_df['category']=comments_df['category_id'].map(id_to_category)\n",
    "comments_df = comments_df[comments_df['category_id']!= 29]\n",
    "comments_df = comments_df[comments_df['category_id']!= 43]\n",
    "\n",
    "main_df = []\n",
    "for ID in tqdm(training_id):\n",
    "    this_category = []\n",
    "    this_category.append(ID)\n",
    "    this_category.append(id_to_category[ID])\n",
    "    comment_str = ''\n",
    "    this_category_comment = comments_df[comments_df['category_id']==ID]\n",
    "    for index,row in this_category_comment.iterrows():\n",
    "        try:\n",
    "            comment_str = comment_str + this_category_comment.at[index,'comment_text']\n",
    "        except:\n",
    "            continue\n",
    "    this_category.append(comment_str)\n",
    "    main_df.append(this_category)\n",
    "\n",
    "df = pd.DataFrame(main_df,columns= ['id','category','comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Select only those categories with large enough data'''\n",
    "\n",
    "df=df.loc[[0,1,2,3,4,6,7,9,10,11,12,13,14,15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "df['comments'] = df['comments'].str.replace('[^\\w\\s#@/:%.,_-]', '', flags=re.UNICODE)\n",
    "'''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers'''\n",
    "def clean_text(text):\n",
    "    text= text.lower()\n",
    "    text = re.sub('\\[.*?\\]','',text)\n",
    "    text = re.sub('[%s]'%re.escape(string.punctuation),'',text)\n",
    "    text = re.sub('\\w*\\d\\w*','',text)\n",
    "    return text\n",
    "clean1= lambda x: clean_text(x)\n",
    "\n",
    "\n",
    "df_clean = pd.DataFrame (df['comments'].apply(clean1))\n",
    "df_clean['category'] = df['category']\n",
    "df_clean=df_clean[['category','comments']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to pickle file and open using pickle \n",
    "\n",
    "df_clean = pd.read_pickle ('df_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Produce a document term matrix of words for each category '''\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv=CountVectorizer(stop_words = 'english')\n",
    "data_cv = cv.fit_transform(df_clean.comments)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(),columns=cv.get_feature_names())\n",
    "data_dtm['category'] = df_clean['category']\n",
    "data_dtm = data_dtm.set_index('category')\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER 1 : WORD MAPPP\n",
    "data=data_dtm.transpose()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create dictionary to count top 30 words in each category'''\n",
    "top_dict = {}\n",
    "for c in data.columns:\n",
    "    try:\n",
    "        top = data[c].sort_values(ascending = False).head(30)\n",
    "        top_dict[c] = list(zip(top.index, top.values))\n",
    "    except:\n",
    "        continue\n",
    "top_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for category in data.columns:\n",
    "    try:\n",
    "        top = [word for (word, count) in top_dict[category]]\n",
    "    except:\n",
    "        # some categories has less than 30 top words\n",
    "        pass\n",
    "    for t in top:\n",
    "        words.append(t)\n",
    "words   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Show words which appear most commonly across categories'''\n",
    "\n",
    "from collections import Counter\n",
    "Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Make stop words include those words which appear most commonly in over half the categories'''\n",
    "\n",
    "add_stop_words = [word for word, count in Counter(words).most_common() if count > 7]\n",
    "add_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Re-construct the dtm with new stop words'''\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union (add_stop_words)\n",
    "cv=CountVectorizer(stop_words=stop_words)\n",
    "data_cv = cv.fit_transform(df_clean.comments)\n",
    "data_stop = pd.DataFrame (data_cv.toarray(),columns=cv.get_feature_names())\n",
    "\n",
    "data_stop['category']=df['category']\n",
    "data_stop = data_stop.set_index('category')\n",
    "data_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "wc = WordCloud(stopwords=stop_words, background_color=\"white\", colormap=\"Dark2\",\n",
    "               max_font_size=150, random_state=42)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 6]\n",
    "\n",
    "cat_names = df_clean['category'].tolist()\n",
    "\n",
    "df_clean.set_index('category',inplace=True)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, cat in enumerate(data.columns):\n",
    "    try:\n",
    "        wc.generate(df_clean.comments[cat])\n",
    "    except:\n",
    "        pass\n",
    "    plt.subplot(4, 4, index+1)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(cat_names[index])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER 2: Amount of profanity\n",
    "data_bad_words = pd.DataFrame (data= data_stop.transpose())\n",
    "data_bad_words = data_bad_words.loc[['fucking','fuck', 'shit']]\n",
    "data_bad_words = data_bad_words.transpose()\n",
    "data_bad_words['f_word'] = data_bad_words['fucking']+data_bad_words['fuck']\n",
    "data_bad_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "for i in range(len(cat_names)):\n",
    "    x = data_bad_words.f_word.loc[cat_names[i]]\n",
    "    y = data_bad_words.shit.loc[cat_names[i]]\n",
    "    plt.scatter(x, y, color='blue')\n",
    "    plt.text(x+1.5, y+0.5, cat_names[i], fontsize=10)\n",
    "    plt.xlim(-5, 5000) \n",
    "    \n",
    "plt.title('Number of Bad Words', fontsize=20)\n",
    "plt.xlabel('Number of F Bombs', fontsize=15)\n",
    "plt.ylabel('Number of S Words', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
