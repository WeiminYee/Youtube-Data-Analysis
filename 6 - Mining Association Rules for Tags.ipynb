{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining Association Rules for tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "cwd = Path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import OrderedDict\n",
    "from itertools import combinations\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "RANDOM = 42\n",
    "seed(RANDOM)\n",
    "np.random.seed(RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(cwd/'output'/\"videos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.drop_duplicates(subset='video_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_total</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>date</th>\n",
       "      <th>likes_log</th>\n",
       "      <th>views_log</th>\n",
       "      <th>dislikes_log</th>\n",
       "      <th>comment_log</th>\n",
       "      <th>category_name</th>\n",
       "      <th>like_rate</th>\n",
       "      <th>dislike_rate</th>\n",
       "      <th>comment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XpVt6Z1Gjjo</td>\n",
       "      <td>1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...</td>\n",
       "      <td>Logan Paul Vlogs</td>\n",
       "      <td>24</td>\n",
       "      <td>logan paul vlog|logan paul|logan|paul|olympics...</td>\n",
       "      <td>4394029</td>\n",
       "      <td>320053</td>\n",
       "      <td>5931</td>\n",
       "      <td>46245</td>\n",
       "      <td>https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>12.676245</td>\n",
       "      <td>15.295757</td>\n",
       "      <td>8.688117</td>\n",
       "      <td>10.741730</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>7.283816</td>\n",
       "      <td>0.134979</td>\n",
       "      <td>1.052451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K4wEI5zhHB0</td>\n",
       "      <td>iPhone X — Introducing iPhone X — Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>28</td>\n",
       "      <td>Apple|iPhone 10|iPhone Ten|iPhone|Portrait Lig...</td>\n",
       "      <td>7860119</td>\n",
       "      <td>185853</td>\n",
       "      <td>26679</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.ytimg.com/vi/K4wEI5zhHB0/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>12.132717</td>\n",
       "      <td>15.877312</td>\n",
       "      <td>10.191670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>2.364506</td>\n",
       "      <td>0.339422</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cLdxuaxaQwc</td>\n",
       "      <td>My Response</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>22</td>\n",
       "      <td>[none]</td>\n",
       "      <td>5845909</td>\n",
       "      <td>576597</td>\n",
       "      <td>39774</td>\n",
       "      <td>170708</td>\n",
       "      <td>https://i.ytimg.com/vi/cLdxuaxaQwc/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>13.264901</td>\n",
       "      <td>15.581253</td>\n",
       "      <td>10.590994</td>\n",
       "      <td>12.047716</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>9.863257</td>\n",
       "      <td>0.680373</td>\n",
       "      <td>2.920128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WYYvHb03Eog</td>\n",
       "      <td>Apple iPhone X first look</td>\n",
       "      <td>The Verge</td>\n",
       "      <td>28</td>\n",
       "      <td>apple iphone x hands on|Apple iPhone X|iPhone ...</td>\n",
       "      <td>2642103</td>\n",
       "      <td>24975</td>\n",
       "      <td>4542</td>\n",
       "      <td>12829</td>\n",
       "      <td>https://i.ytimg.com/vi/WYYvHb03Eog/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>10.125671</td>\n",
       "      <td>14.787086</td>\n",
       "      <td>8.421343</td>\n",
       "      <td>9.459541</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>0.945270</td>\n",
       "      <td>0.171909</td>\n",
       "      <td>0.485560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sjlHnJvXdQs</td>\n",
       "      <td>iPhone X (parody)</td>\n",
       "      <td>jacksfilms</td>\n",
       "      <td>23</td>\n",
       "      <td>jacksfilms|parody|parodies|iphone|iphone x|iph...</td>\n",
       "      <td>1168130</td>\n",
       "      <td>96666</td>\n",
       "      <td>568</td>\n",
       "      <td>6666</td>\n",
       "      <td>https://i.ytimg.com/vi/sjlHnJvXdQs/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>11.479027</td>\n",
       "      <td>13.970916</td>\n",
       "      <td>6.343880</td>\n",
       "      <td>8.804925</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>8.275278</td>\n",
       "      <td>0.048625</td>\n",
       "      <td>0.570656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  XpVt6Z1Gjjo  1 YEAR OF VLOGGING -- HOW LOGAN PAUL CHANGED Y...   \n",
       "1  K4wEI5zhHB0            iPhone X — Introducing iPhone X — Apple   \n",
       "2  cLdxuaxaQwc                                        My Response   \n",
       "3  WYYvHb03Eog                          Apple iPhone X first look   \n",
       "4  sjlHnJvXdQs                                  iPhone X (parody)   \n",
       "\n",
       "      channel_title  category_id  \\\n",
       "0  Logan Paul Vlogs           24   \n",
       "1             Apple           28   \n",
       "2         PewDiePie           22   \n",
       "3         The Verge           28   \n",
       "4        jacksfilms           23   \n",
       "\n",
       "                                                tags    views   likes  \\\n",
       "0  logan paul vlog|logan paul|logan|paul|olympics...  4394029  320053   \n",
       "1  Apple|iPhone 10|iPhone Ten|iPhone|Portrait Lig...  7860119  185853   \n",
       "2                                             [none]  5845909  576597   \n",
       "3  apple iphone x hands on|Apple iPhone X|iPhone ...  2642103   24975   \n",
       "4  jacksfilms|parody|parodies|iphone|iphone x|iph...  1168130   96666   \n",
       "\n",
       "   dislikes  comment_total                                  thumbnail_link  \\\n",
       "0      5931          46245  https://i.ytimg.com/vi/XpVt6Z1Gjjo/default.jpg   \n",
       "1     26679              0  https://i.ytimg.com/vi/K4wEI5zhHB0/default.jpg   \n",
       "2     39774         170708  https://i.ytimg.com/vi/cLdxuaxaQwc/default.jpg   \n",
       "3      4542          12829  https://i.ytimg.com/vi/WYYvHb03Eog/default.jpg   \n",
       "4       568           6666  https://i.ytimg.com/vi/sjlHnJvXdQs/default.jpg   \n",
       "\n",
       "    date  likes_log  views_log  dislikes_log  comment_log  \\\n",
       "0  13.09  12.676245  15.295757      8.688117    10.741730   \n",
       "1  13.09  12.132717  15.877312     10.191670     0.000000   \n",
       "2  13.09  13.264901  15.581253     10.590994    12.047716   \n",
       "3  13.09  10.125671  14.787086      8.421343     9.459541   \n",
       "4  13.09  11.479027  13.970916      6.343880     8.804925   \n",
       "\n",
       "          category_name  like_rate  dislike_rate  comment_rate  \n",
       "0         Entertainment   7.283816      0.134979      1.052451  \n",
       "1  Science & Technology   2.364506      0.339422      0.000000  \n",
       "2        People & Blogs   9.863257      0.680373      2.920128  \n",
       "3  Science & Technology   0.945270      0.171909      0.485560  \n",
       "4                Comedy   8.275278      0.048625      0.570656  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    logan paul vlog|logan paul|logan|paul|olympics...\n",
       "1    Apple|iPhone 10|iPhone Ten|iPhone|Portrait Lig...\n",
       "2                                               [none]\n",
       "3    apple iphone x hands on|Apple iPhone X|iPhone ...\n",
       "4    jacksfilms|parody|parodies|iphone|iphone x|iph...\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logan paul vlog|logan paul|logan|paul|olympics|logan paul youtube|vlog|daily|comedy|hollywood|parrot|maverick|bird|maverick clothes|diamond play button|logan paul diamond play button|10M subscribers|logan paul 1 year vlogging|1 year vlog|dwarf mamba play button|logan paul history|youtube history|10M|10M plaque|youtube button|diamond button|logang|logang 4 life'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_total</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>date</th>\n",
       "      <th>likes_log</th>\n",
       "      <th>views_log</th>\n",
       "      <th>dislikes_log</th>\n",
       "      <th>comment_log</th>\n",
       "      <th>category_name</th>\n",
       "      <th>like_rate</th>\n",
       "      <th>dislike_rate</th>\n",
       "      <th>comment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cLdxuaxaQwc</td>\n",
       "      <td>My Response</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>22</td>\n",
       "      <td>[none]</td>\n",
       "      <td>5845909</td>\n",
       "      <td>576597</td>\n",
       "      <td>39774</td>\n",
       "      <td>170708</td>\n",
       "      <td>https://i.ytimg.com/vi/cLdxuaxaQwc/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>13.264901</td>\n",
       "      <td>15.581253</td>\n",
       "      <td>10.590994</td>\n",
       "      <td>12.047716</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>9.863257</td>\n",
       "      <td>0.680373</td>\n",
       "      <td>2.920128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>bAon04ZJhHE</td>\n",
       "      <td>Season 21 Preview: White People Renovating Houses</td>\n",
       "      <td>South Park Studios</td>\n",
       "      <td>20</td>\n",
       "      <td>[none]</td>\n",
       "      <td>182676</td>\n",
       "      <td>3752</td>\n",
       "      <td>165</td>\n",
       "      <td>1163</td>\n",
       "      <td>https://i.ytimg.com/vi/bAon04ZJhHE/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>8.230311</td>\n",
       "      <td>12.115475</td>\n",
       "      <td>5.111988</td>\n",
       "      <td>7.059618</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>2.053910</td>\n",
       "      <td>0.090324</td>\n",
       "      <td>0.636646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>bp6uJJJMaLs</td>\n",
       "      <td>Things you need to know about Pennywise</td>\n",
       "      <td>Jenny Nicholson</td>\n",
       "      <td>1</td>\n",
       "      <td>[none]</td>\n",
       "      <td>39338</td>\n",
       "      <td>2377</td>\n",
       "      <td>103</td>\n",
       "      <td>484</td>\n",
       "      <td>https://i.ytimg.com/vi/bp6uJJJMaLs/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>7.774015</td>\n",
       "      <td>10.579972</td>\n",
       "      <td>4.644391</td>\n",
       "      <td>6.184149</td>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>6.042503</td>\n",
       "      <td>0.261833</td>\n",
       "      <td>1.230362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>UpONjs5kLPc</td>\n",
       "      <td>Los jugadores de Sacachispas entraron vestidos...</td>\n",
       "      <td>Futbol La Pasion</td>\n",
       "      <td>17</td>\n",
       "      <td>[none]</td>\n",
       "      <td>53712</td>\n",
       "      <td>203</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>https://i.ytimg.com/vi/UpONjs5kLPc/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>5.318120</td>\n",
       "      <td>10.891410</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0.377942</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.046545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>c3pFWJCQy5E</td>\n",
       "      <td>Update: Problem with Chemo Pills</td>\n",
       "      <td>Courtelizz1</td>\n",
       "      <td>26</td>\n",
       "      <td>[none]</td>\n",
       "      <td>108839</td>\n",
       "      <td>3677</td>\n",
       "      <td>107</td>\n",
       "      <td>732</td>\n",
       "      <td>https://i.ytimg.com/vi/c3pFWJCQy5E/default.jpg</td>\n",
       "      <td>13.09</td>\n",
       "      <td>8.210124</td>\n",
       "      <td>11.597634</td>\n",
       "      <td>4.682131</td>\n",
       "      <td>6.597146</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "      <td>3.378385</td>\n",
       "      <td>0.098310</td>\n",
       "      <td>0.672553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                                              title  \\\n",
       "2    cLdxuaxaQwc                                        My Response   \n",
       "56   bAon04ZJhHE  Season 21 Preview: White People Renovating Houses   \n",
       "74   bp6uJJJMaLs            Things you need to know about Pennywise   \n",
       "133  UpONjs5kLPc  Los jugadores de Sacachispas entraron vestidos...   \n",
       "164  c3pFWJCQy5E                   Update: Problem with Chemo Pills   \n",
       "\n",
       "          channel_title  category_id    tags    views   likes  dislikes  \\\n",
       "2             PewDiePie           22  [none]  5845909  576597     39774   \n",
       "56   South Park Studios           20  [none]   182676    3752       165   \n",
       "74      Jenny Nicholson            1  [none]    39338    2377       103   \n",
       "133    Futbol La Pasion           17  [none]    53712     203         4   \n",
       "164         Courtelizz1           26  [none]   108839    3677       107   \n",
       "\n",
       "     comment_total                                  thumbnail_link   date  \\\n",
       "2           170708  https://i.ytimg.com/vi/cLdxuaxaQwc/default.jpg  13.09   \n",
       "56            1163  https://i.ytimg.com/vi/bAon04ZJhHE/default.jpg  13.09   \n",
       "74             484  https://i.ytimg.com/vi/bp6uJJJMaLs/default.jpg  13.09   \n",
       "133             25  https://i.ytimg.com/vi/UpONjs5kLPc/default.jpg  13.09   \n",
       "164            732  https://i.ytimg.com/vi/c3pFWJCQy5E/default.jpg  13.09   \n",
       "\n",
       "     likes_log  views_log  dislikes_log  comment_log     category_name  \\\n",
       "2    13.264901  15.581253     10.590994    12.047716    People & Blogs   \n",
       "56    8.230311  12.115475      5.111988     7.059618            Gaming   \n",
       "74    7.774015  10.579972      4.644391     6.184149  Film & Animation   \n",
       "133   5.318120  10.891410      1.609438     3.258097            Sports   \n",
       "164   8.210124  11.597634      4.682131     6.597146     Howto & Style   \n",
       "\n",
       "     like_rate  dislike_rate  comment_rate  \n",
       "2     9.863257      0.680373      2.920128  \n",
       "56    2.053910      0.090324      0.636646  \n",
       "74    6.042503      0.261833      1.230362  \n",
       "133   0.377942      0.007447      0.046545  \n",
       "164   3.378385      0.098310      0.672553  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['tags']=='[none]'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = df.apply(lambda row: row['tags'].split(\"|\"), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"\" and \"[none]\" and change to lower case and strip leading and trailing whitespace\n",
    "for i in range(len(records)):\n",
    "    records[i] = [tag.lower().strip() for tag in records[i] if tag != \"\" and tag != \"[none]\"]\n",
    "# Remove empty records\n",
    "records = [record for record in records if len(record) != 0]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many unique tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28281"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tags = set()\n",
    "for record in records:\n",
    "    unique_tags.update(set(record))\n",
    "len(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28281/28281 [00:25<00:00, 1124.40it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_tags_and_counts = {} # tag:count\n",
    "for unique_tag in tqdm(unique_tags):\n",
    "    for record in records:\n",
    "        if unique_tag not in record:\n",
    "            continue\n",
    "        if unique_tag not in unique_tags_and_counts:\n",
    "            unique_tags_and_counts[unique_tag] = 1\n",
    "        else:\n",
    "            unique_tags_and_counts[unique_tag] += 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('funny', 325),\n",
       " ('comedy', 250),\n",
       " ('2017', 140),\n",
       " ('vlog', 140),\n",
       " ('makeup', 125),\n",
       " ('interview', 114),\n",
       " ('music', 113),\n",
       " ('humor', 112),\n",
       " ('how to', 112),\n",
       " ('news', 107),\n",
       " ('football', 104),\n",
       " ('beauty', 103),\n",
       " ('trailer', 102),\n",
       " ('video', 100),\n",
       " ('celebrity', 98),\n",
       " ('talk show', 93),\n",
       " ('tutorial', 91),\n",
       " ('review', 85),\n",
       " ('food', 84),\n",
       " ('fashion', 84)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to see top 20 1-itemsets\n",
    "sorted(list(unique_tags_and_counts.items()), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many 1-itemsets have <= n occurence?\n",
    "def less_than_n_occurence(n, unique_tags_and_counts):\n",
    "    count = 0\n",
    "    for k, v in unique_tags_and_counts.items():\n",
    "        assert(v != 0)\n",
    "        if v <= n:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.12464198578552% of 1-itemsets have <= 1 occurence\n",
      "86.05424136345957% of 1-itemsets have <= 2 occurence\n",
      "90.79240479473852% of 1-itemsets have <= 3 occurence\n",
      "93.07662388175807% of 1-itemsets have <= 4 occurence\n",
      "94.62183091121247% of 1-itemsets have <= 5 occurence\n",
      "95.77808422615891% of 1-itemsets have <= 6 occurence\n",
      "96.5418478837382% of 1-itemsets have <= 7 occurence\n",
      "97.13588628407764% of 1-itemsets have <= 8 occurence\n",
      "97.50716028428981% of 1-itemsets have <= 9 occurence\n"
     ]
    }
   ],
   "source": [
    "# Change range to your liking\n",
    "for i in range(1, 10, 1):\n",
    "    count = less_than_n_occurence(i, unique_tags_and_counts)\n",
    "    print(f\"{count*100/len(unique_tags)}% of 1-itemsets have <= {i} occurence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.005\n",
    "min_sup_count = min_sup*len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.41"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_sup_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_one_itemset_with_counts = [item for item in sorted(list(unique_tags_and_counts.items()), key=lambda x: x[1], reverse=True)\\\n",
    "                                    if item[1] > min_sup_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_one_itemset = [i[0] for i in frequent_one_itemset_with_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['funny',\n",
       " 'comedy',\n",
       " '2017',\n",
       " 'vlog',\n",
       " 'makeup',\n",
       " 'interview',\n",
       " 'music',\n",
       " 'humor',\n",
       " 'how to',\n",
       " 'news',\n",
       " 'football',\n",
       " 'beauty',\n",
       " 'trailer',\n",
       " 'video',\n",
       " 'celebrity',\n",
       " 'talk show',\n",
       " 'tutorial',\n",
       " 'review',\n",
       " 'food',\n",
       " 'fashion',\n",
       " 'television',\n",
       " 'pop',\n",
       " 'celebrities',\n",
       " 'live',\n",
       " 'funny video',\n",
       " 'hollywood',\n",
       " 'comedian',\n",
       " 'science',\n",
       " 'late night',\n",
       " 'clip',\n",
       " 'new',\n",
       " 'diy',\n",
       " 'show',\n",
       " 'highlights',\n",
       " 'jokes',\n",
       " 'halloween',\n",
       " 'nbc',\n",
       " 'soccer',\n",
       " 'highlight',\n",
       " 'sports',\n",
       " 'youtube',\n",
       " 'games',\n",
       " 'family',\n",
       " 'fun',\n",
       " 'vlogging',\n",
       " 'haul',\n",
       " 'film',\n",
       " 'comedic',\n",
       " 'style',\n",
       " 'london']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_one_itemset[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change records to l-order\n",
    "for i in range(len(records)):\n",
    "    records[i] = [tag for tag in records[i] if tag in frequent_one_itemset]\n",
    "    records[i] = sorted(records[i], key=lambda x: frequent_one_itemset.index(x), reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['comedy', 'vlog', 'hollywood', 'daily'],\n",
       " ['apple', 'iphone'],\n",
       " ['apple', 'iphone', 'iphone x'],\n",
       " ['parody', 'apple', 'iphone 8', 'iphone', 'iphone x'],\n",
       " ['comedy', 'trailer', 'film', 'movie', 'official', 'hd'],\n",
       " ['funny',\n",
       "  'comedy',\n",
       "  'humor',\n",
       "  'talk show',\n",
       "  'television',\n",
       "  'late night',\n",
       "  'nbc',\n",
       "  'nbc tv',\n",
       "  'parody',\n",
       "  'satire',\n",
       "  'host',\n",
       "  'promo',\n",
       "  'stand-up',\n",
       "  'news satire'],\n",
       " ['iphone 8', 'iphone x', 'iphone x', 'iphone 8 plus'],\n",
       " ['vlog',\n",
       "  'vlogging',\n",
       "  'vlogger',\n",
       "  'daily',\n",
       "  'kids',\n",
       "  'home',\n",
       "  'house',\n",
       "  'vlogs',\n",
       "  'family friendly',\n",
       "  'dog',\n",
       "  'dog',\n",
       "  'girlfriend',\n",
       "  'day'],\n",
       " [],\n",
       " ['funny', 'comedy', 'humor', 'sketch', 'sketch comedy', 'amazon'],\n",
       " ['interview',\n",
       "  'best',\n",
       "  'lelepons',\n",
       "  'shots',\n",
       "  'marshemllo',\n",
       "  'alesso',\n",
       "  'marshmello',\n",
       "  'shotsstudios',\n",
       "  'anwar',\n",
       "  'hannahstocking',\n",
       "  'rudymancuso',\n",
       "  'inannasarkis',\n",
       "  'inanna'],\n",
       " ['funny',\n",
       "  'interview',\n",
       "  'humor',\n",
       "  'video',\n",
       "  'talk show',\n",
       "  'television',\n",
       "  'celebrities',\n",
       "  'funny video',\n",
       "  'clip',\n",
       "  'show',\n",
       "  'jokes',\n",
       "  'nbc',\n",
       "  'highlight',\n",
       "  'comedic',\n",
       "  'snl',\n",
       "  'nbc tv',\n",
       "  'talent',\n",
       "  'variety',\n",
       "  'jimmy fallon',\n",
       "  'fallon stand-up',\n",
       "  'tonight',\n",
       "  'comedy sketches',\n",
       "  'the tonight show',\n",
       "  'fallon monologue',\n",
       "  'jimmy',\n",
       "  'mother'],\n",
       " ['video',\n",
       "  'celebrity',\n",
       "  'television',\n",
       "  'celebrities',\n",
       "  'tv',\n",
       "  'official',\n",
       "  'hurricane irma',\n",
       "  'florida',\n",
       "  'watch',\n",
       "  'stars'],\n",
       " ['funny',\n",
       "  'highlights',\n",
       "  'nbc',\n",
       "  'tv',\n",
       "  'entertainment',\n",
       "  'talent',\n",
       "  'talent',\n",
       "  'season 12'],\n",
       " ['2017',\n",
       "  'review',\n",
       "  'apple',\n",
       "  'iphone 8',\n",
       "  'iphone 8',\n",
       "  'unboxing',\n",
       "  'iphone',\n",
       "  'iphone x',\n",
       "  'iphone 8 plus'],\n",
       " ['comedy', 'food', 'buzzfeed', 'girlfriend', 'boyfriend'],\n",
       " ['tutorial', 'weather'],\n",
       " ['funny', 'comedy', 'how to', 'recipe', 'cooking', 'kitchen'],\n",
       " ['funny',\n",
       "  'comedy',\n",
       "  'trailer',\n",
       "  'film',\n",
       "  'official',\n",
       "  'drama',\n",
       "  'official trailer'],\n",
       " ['pop']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement FP-Tree and test with example from lecture notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sublist(ls1, ls2):\n",
    "    def get_all_in(one, another):\n",
    "        for element in one:\n",
    "            if element in another:\n",
    "                yield element\n",
    "\n",
    "    for x1, x2 in zip(get_all_in(ls1, ls2), get_all_in(ls2, ls1)):\n",
    "        if x1 != x2:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPTreeNode:\n",
    "    \n",
    "    def __init__(self, item=None, count=None, parent=None):\n",
    "        self.root = False\n",
    "        self.item = item\n",
    "        self.count = count\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        if parent == None:\n",
    "            self.root = True\n",
    "            self.item = \"{}\"\n",
    "    \n",
    "    def find_child_with_item(self, item):\n",
    "        for child in self.children:\n",
    "            if child.item == item:\n",
    "                return child\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def add(self, record):\n",
    "        if not self.root:\n",
    "            while len(record) != 0 and self.item == record[0]:\n",
    "                self.count += 1\n",
    "                record.pop(0)\n",
    "        if len(record) == 0:\n",
    "            return\n",
    "        child = self.find_child_with_item(record[0])\n",
    "        if child != None:\n",
    "            child.add(record)\n",
    "        else:\n",
    "            self.children.append(FPTreeNode(record[0], 1, self))\n",
    "            self.children[-1].parent = self\n",
    "            self.children[-1].add(record[1:])\n",
    "    \n",
    "    def show(self):\n",
    "        # Only useful for development ...\n",
    "        # BFS to print\n",
    "        queue = []\n",
    "        queue.append(self)\n",
    "        queue.append(None) # as a delimiter\n",
    "        while len(queue) > 1:\n",
    "            cur = queue.pop(0)\n",
    "            if cur == None:\n",
    "                queue.append(None)\n",
    "                print(\"\\n\")\n",
    "            else:\n",
    "                for child in cur.children:\n",
    "                    queue.append(child)\n",
    "                print(f\"{cur.item}:{cur.count} \", end='')\n",
    "    \n",
    "    def get_cpb(self, item):\n",
    "        # Get cpb end with item\n",
    "        # First find the nodes of that item\n",
    "        nodes = []\n",
    "        # DFS to search for the nodes\n",
    "        stack = []\n",
    "        stack.append(self)\n",
    "        while len(stack) > 0:\n",
    "            cur = stack.pop()\n",
    "            if cur.item == item:\n",
    "                nodes.append(cur)\n",
    "            for child in cur.children:\n",
    "                stack.append(child)\n",
    "        # Based on the nodes, find the cpb and count\n",
    "        cpb_and_count = []\n",
    "        for node in nodes:\n",
    "            cpb = []\n",
    "            cur = node\n",
    "            while cur.parent and cur.parent.item != \"{}\":\n",
    "                cpb.append(cur.parent.item)\n",
    "                cur = cur.parent\n",
    "            cpb.reverse()\n",
    "            if len(cpb) == 0:\n",
    "                continue\n",
    "            cpb_and_count.append((cpb, node.count))\n",
    "        cpb_and_count.reverse() # due to stack\n",
    "        return cpb_and_count\n",
    "    \n",
    "    def get_cft(self, item, min_count):\n",
    "        cpb_and_count = self.get_cpb(item)\n",
    "        cft = OrderedDict()\n",
    "        for (pattern, count) in cpb_and_count:\n",
    "            for item in pattern:\n",
    "                if item not in cft:\n",
    "                    cft[item] = count\n",
    "                else:\n",
    "                    cft[item] += count\n",
    "        filtered_cft = OrderedDict()\n",
    "        for k, v in cft.items():\n",
    "            if v >= min_count:\n",
    "                filtered_cft[k] = v\n",
    "        return filtered_cft\n",
    "    \n",
    "    def get_frequent_itemsets(self, one_itemset_list, min_sup_count):\n",
    "        cft_list = [self.get_cft(i, min_sup_count) for i in one_itemset_list]\n",
    "        frequent_itemsets = []\n",
    "        for i in range(len(cft_list)):\n",
    "            cft_items = list(cft_list[i])\n",
    "            end_base = one_itemset_list[i]\n",
    "            frequent_itemsets.append([end_base])\n",
    "            if len(cft_items) == 0:\n",
    "                continue\n",
    "            for i in range(1, len(cft_items)+1):\n",
    "                i_combinations = [list(j) for j in list(combinations(cft_items, i))]\n",
    "                for i_combination in i_combinations:\n",
    "                    i_combination.append(end_base)\n",
    "                frequent_itemsets.extend(i_combinations)\n",
    "        return frequent_itemsets\n",
    "    \n",
    "    def get_maximal_frequent_itemsets(self, one_itemset_list, min_sup_count, at_least_two=True):\n",
    "        cft_list = [self.get_cft(i, min_sup_count) for i in one_itemset_list]\n",
    "        frequent_itemsets = []\n",
    "        for i in range(len(cft_list)):\n",
    "            cft_items = list(cft_list[i].items())\n",
    "            if at_least_two and len(cft_items) == 0:\n",
    "                continue\n",
    "            min_count_in_cft = min([i[1] for i in cft_items])\n",
    "            end_base = one_itemset_list[i]\n",
    "            cft_items_w_count = ([i[0] for i in cft_items] + [end_base], min_count_in_cft) \n",
    "            frequent_itemsets.append(cft_items_w_count)\n",
    "        remove_idx = set()\n",
    "        for i in range(len(frequent_itemsets)):\n",
    "            for j in range(len(frequent_itemsets)):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                if set(frequent_itemsets[i][0]).issubset(set(frequent_itemsets[j][0])):\n",
    "                    remove_idx.add(i)\n",
    "        frequent_itemsets = [frequent_itemsets[i] for i in range(len(frequent_itemsets)) if i not in remove_idx]\n",
    "        return frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{1, 2}.issubset({1, 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_records = [\n",
    "    ['f', 'c', 'a', 'm', 'p'],\n",
    "    ['f', 'c', 'a', 'b', 'm'],\n",
    "    ['f', 'b'],\n",
    "    ['c', 'b', 'p'],\n",
    "    ['f', 'c', 'a', 'm', 'p']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_tree = FPTreeNode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_record in test_records:\n",
    "    fp_tree.add(test_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}:None \n",
      "\n",
      "f:4 c:1 \n",
      "\n",
      "c:3 b:1 b:1 \n",
      "\n",
      "a:3 p:1 \n",
      "\n",
      "m:2 b:1 \n",
      "\n",
      "p:2 m:1 "
     ]
    }
   ],
   "source": [
    "fp_tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['f', 'c', 'a', 'm'], 2), (['c', 'b'], 1)]\n",
      "[(['f', 'c', 'a'], 2), (['f', 'c', 'a', 'b'], 1)]\n",
      "[(['f', 'c', 'a'], 1), (['f'], 1), (['c'], 1)]\n",
      "[(['f', 'c'], 3)]\n",
      "[(['f'], 3)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for char in \"pmbacf\":\n",
    "    print(fp_tree.get_cpb(char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f', 3), ('c', 3), ('a', 3)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fp_tree.get_cft('m', 3).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('c', 3)])\n",
      "OrderedDict([('f', 3), ('c', 3), ('a', 3)])\n",
      "OrderedDict()\n",
      "OrderedDict([('f', 3), ('c', 3)])\n",
      "OrderedDict([('f', 3)])\n",
      "OrderedDict()\n"
     ]
    }
   ],
   "source": [
    "for char in \"pmbacf\":\n",
    "    print(fp_tree.get_cft(char, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['p'],\n",
       " ['c', 'p'],\n",
       " ['m'],\n",
       " ['f', 'm'],\n",
       " ['c', 'm'],\n",
       " ['a', 'm'],\n",
       " ['f', 'c', 'm'],\n",
       " ['f', 'a', 'm'],\n",
       " ['c', 'a', 'm'],\n",
       " ['f', 'c', 'a', 'm'],\n",
       " ['b'],\n",
       " ['a'],\n",
       " ['f', 'a'],\n",
       " ['c', 'a'],\n",
       " ['f', 'c', 'a'],\n",
       " ['c'],\n",
       " ['f', 'c'],\n",
       " ['f']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_tree.get_frequent_itemsets(\"pmbacf\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['c', 'p'], 3), (['f', 'c', 'a', 'm'], 3)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_tree.get_maximal_frequent_itemsets(\"pmbacf\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_empty_subsets(frequent_itemset):\n",
    "    # NOTE: for frequent itemset of size n, only segment into pairs of subsets of sizes 1, n-1\n",
    "    # RATIONALE: save time, and it is pointless as we will find out later\n",
    "    clone = frequent_itemset[0][:]\n",
    "    frequent_itemset = set(frequent_itemset[0])\n",
    "    rule_combinations = [set(j) for j in list(combinations(frequent_itemset, 1))]\n",
    "    rule_combinations = [[j, frequent_itemset.difference(j)] for j in rule_combinations]\n",
    "    for rule_combination in rule_combinations:\n",
    "        rule_combination[0] = sorted(list(rule_combination[0]), key=lambda x: clone.index(x), reverse=False)\n",
    "        rule_combination[1] = sorted(list(rule_combination[1]), key=lambda x: clone.index(x), reverse=False)\n",
    "    return rule_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['f'], ['c', 'a', 'm']],\n",
       " [['m'], ['f', 'c', 'a']],\n",
       " [['c'], ['f', 'a', 'm']],\n",
       " [['a'], ['f', 'c', 'm']]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_non_empty_subsets((['f', 'c', 'a', 'm'], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, now for actual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode into integer \n",
    "counter = 0\n",
    "item_to_int_map = {}\n",
    "int_to_item_map = {}\n",
    "for record in records:\n",
    "    for item in record:\n",
    "        if item in item_to_int_map:\n",
    "            continue\n",
    "        item_to_int_map[item] = counter\n",
    "        int_to_item_map[counter] = item\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(records)):\n",
    "    for j in range(len(records[i])):\n",
    "        records[i][j] = item_to_int_map[records[i][j]]\n",
    "for i in range(len(frequent_one_itemset)):\n",
    "    frequent_one_itemset[i] = item_to_int_map[frequent_one_itemset[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_tree = FPTreeNode()\n",
    "for record in records:\n",
    "    fp_tree.add(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.41"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_sup_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on maximal only. RAM no space to store all and maximal is more meaningful\n",
    "maximal_frequent_itemsets = fp_tree.get_maximal_frequent_itemsets(frequent_one_itemset, min_sup_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rule(records, no_conf_rule):\n",
    "    itemset = no_conf_rule[0] + no_conf_rule[1]\n",
    "    support_count_total = 0\n",
    "    support_count_lhs = 0\n",
    "    for record in records:\n",
    "        if sublist(itemset, record):\n",
    "            support_count_total += 1\n",
    "        if sublist(no_conf_rule[0], record):\n",
    "            support_count_lhs += 1\n",
    "    return no_conf_rule + [support_count_total/len(records), support_count_total/support_count_lhs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:03<00:00, 31.44it/s]\n"
     ]
    }
   ],
   "source": [
    "rules = []\n",
    "for frequent_itemset in tqdm(maximal_frequent_itemsets):\n",
    "    no_conf_rules = get_non_empty_subsets(frequent_itemset)\n",
    "    for no_conf_rule in no_conf_rules:\n",
    "        rules.append(get_rule(records, no_conf_rule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990914990266061"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min confidence of rules\n",
    "min([rule[3] for rule in rules])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Means that if you permutate all possible rules of a maximal frequent set for all maximal frequent sets, the worst confidence of a rule is 99.4%\n",
    "\n",
    "The existence of an item in maximal frequent set means implies item -> the rest of the items in the maximal frequent set with confidence of at least 99.4%\n",
    "\n",
    "We can simply analyze maximal frequent itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to item names\n",
    "for i in range(len(maximal_frequent_itemsets)):\n",
    "    for j in range(len(maximal_frequent_itemsets[i][0])):\n",
    "        maximal_frequent_itemsets[i][0][j] = int_to_item_map[maximal_frequent_itemsets[i][0][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort of frequency\n",
    "maximal_frequent_itemsets.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['funny',\n",
       "   'comedy',\n",
       "   'humor',\n",
       "   'celebrity',\n",
       "   'celebrities',\n",
       "   'funny video',\n",
       "   'hollywood',\n",
       "   'comedian',\n",
       "   'late night',\n",
       "   'talk show',\n",
       "   'interview',\n",
       "   'video',\n",
       "   'television',\n",
       "   'clip',\n",
       "   'show',\n",
       "   'jokes'],\n",
       "  29),\n",
       " (['funny',\n",
       "   'interview',\n",
       "   'humor',\n",
       "   'video',\n",
       "   'talk show',\n",
       "   'television',\n",
       "   'celebrities',\n",
       "   'funny video',\n",
       "   'clip',\n",
       "   'show',\n",
       "   'jokes',\n",
       "   'nbc',\n",
       "   'highlight',\n",
       "   'comedic',\n",
       "   'snl',\n",
       "   'nbc tv',\n",
       "   'talent',\n",
       "   'variety',\n",
       "   'jimmy fallon',\n",
       "   'fallon stand-up',\n",
       "   'tonight',\n",
       "   'comedy sketches',\n",
       "   'the tonight show',\n",
       "   'fallon monologue'],\n",
       "  29),\n",
       " (['technology', 'tech'], 28),\n",
       " (['nba', 'basketball'], 28),\n",
       " (['trailer', 'official trailer'], 25),\n",
       " (['funny', 'fun'], 24),\n",
       " (['funny', 'comedy', 'late night', 'host'], 23),\n",
       " (['funny', 'how to', 'vlog', 'makeup', 'beauty', 'tutorial'], 22),\n",
       " (['funny',\n",
       "   'comedy',\n",
       "   'humor',\n",
       "   'talk show',\n",
       "   'comedian',\n",
       "   'clip',\n",
       "   'show',\n",
       "   'television',\n",
       "   'interview',\n",
       "   'video',\n",
       "   'celebrities',\n",
       "   'funny video',\n",
       "   'jokes',\n",
       "   'nbc',\n",
       "   'highlight',\n",
       "   'comedic'],\n",
       "  22),\n",
       " (['trailer', 'movies'], 22),\n",
       " (['show', 'talk'], 22),\n",
       " (['funny', 'comedy', 'comedian', 'clip', 'comedic', 'jimmy'], 22),\n",
       " (['comedy',\n",
       "   'trailer',\n",
       "   'humor',\n",
       "   'interview',\n",
       "   'funny',\n",
       "   'talk show',\n",
       "   'video',\n",
       "   'television'],\n",
       "  21),\n",
       " (['trailer', 'film', 'movie'], 21),\n",
       " (['science', 'education'], 21),\n",
       " (['comedy', 'parody', 'funny', 'satire'], 21),\n",
       " (['funny', 'comedy', 'laugh'], 21),\n",
       " (['vox', 'explain', 'vox.com'], 21),\n",
       " (['funny',\n",
       "   'music',\n",
       "   'video',\n",
       "   'interview',\n",
       "   'humor',\n",
       "   'talk show',\n",
       "   'television',\n",
       "   'celebrities',\n",
       "   'funny video',\n",
       "   'clip',\n",
       "   'show',\n",
       "   'jokes',\n",
       "   'nbc',\n",
       "   'highlight',\n",
       "   'comedic',\n",
       "   'snl'],\n",
       "  20),\n",
       " (['comedy', 'sketch', 'funny', 'hilarious'], 20),\n",
       " (['football', 'soccer', 'premier league'], 20),\n",
       " (['trailer', 'streaming'], 20),\n",
       " (['comedy', 'funny', 'vlog'], 19),\n",
       " (['football', 'highlights', 'soccer'], 19),\n",
       " (['funny',\n",
       "   'interview',\n",
       "   'humor',\n",
       "   'video',\n",
       "   'talk show',\n",
       "   'television',\n",
       "   'celebrities',\n",
       "   'funny video',\n",
       "   'clip',\n",
       "   'show',\n",
       "   'jokes',\n",
       "   'nbc',\n",
       "   '2017',\n",
       "   'highlights',\n",
       "   'football',\n",
       "   'highlight'],\n",
       "  19),\n",
       " (['makeup', 'beauty', 'tutorial', 'cosmetics'], 19),\n",
       " (['rap', 'hip hop'], 19),\n",
       " (['vlog', 'vlogs'], 19),\n",
       " (['apple', 'iphone'], 19),\n",
       " (['fashion', 'clothes'], 19),\n",
       " (['vlog', 'makeup', 'how to', '2017', 'beauty'], 18),\n",
       " (['funny', 'comedy', 'music', 'live'], 18),\n",
       " (['interview',\n",
       "   'television',\n",
       "   'celebrities',\n",
       "   'funny',\n",
       "   'clip',\n",
       "   'talk show',\n",
       "   'live',\n",
       "   'humor',\n",
       "   'video',\n",
       "   'funny video',\n",
       "   'show'],\n",
       "  18),\n",
       " (['vlog', 'makeup', 'beauty', 'haul'], 18),\n",
       " (['comedy', 'humor', 'funny', 'sketch'], 18),\n",
       " (['music', 'music video'], 18),\n",
       " (['makeup', 'how to', 'tutorial', 'beauty', 'makeup tutorial'], 18),\n",
       " (['cute', 'vlog', 'daily', 'british', 'puppy'], 18),\n",
       " (['funny', 'games', 'gaming'], 18),\n",
       " (['haul', 'shopping'], 18),\n",
       " (['highlights', 'goals'], 18),\n",
       " (['food', 'recipe', 'cooking', 'kitchen', 'chef'], 18),\n",
       " (['dad', 'father'], 18),\n",
       " (['vlog',\n",
       "   'daily',\n",
       "   'british',\n",
       "   'puppy',\n",
       "   'zoella',\n",
       "   'zoe',\n",
       "   'pointlessblog',\n",
       "   'nala'],\n",
       "  18),\n",
       " (['funny',\n",
       "   'comedy',\n",
       "   'humor',\n",
       "   'celebrity',\n",
       "   'talk show',\n",
       "   'celebrities',\n",
       "   'funny video',\n",
       "   'hollywood',\n",
       "   'comedian',\n",
       "   'late night',\n",
       "   'jokes',\n",
       "   'famous',\n",
       "   'joke',\n",
       "   'cbs',\n",
       "   'celeb',\n",
       "   'funny videos',\n",
       "   'stephen colbert',\n",
       "   'impressions',\n",
       "   'monologue',\n",
       "   'james corden',\n",
       "   'colbert',\n",
       "   'corden',\n",
       "   'the late late show',\n",
       "   'late late show',\n",
       "   'david letterman',\n",
       "   'skits',\n",
       "   'letterman',\n",
       "   'bit',\n",
       "   'the late show',\n",
       "   'late show'],\n",
       "  18),\n",
       " (['makeup', 'fashion', 'beauty', 'style'], 17),\n",
       " (['funny', 'vlog', 'cute'], 17),\n",
       " (['science', 'technology'], 17),\n",
       " (['donald trump', 'politics'], 17),\n",
       " (['comedy', 'trailer', 'drama'], 17),\n",
       " (['football', 'highlights', 'highlight', 'sp:ty=high'], 17),\n",
       " (['vlog', 'daily', 'house'], 17),\n",
       " (['comedy', 'trailer', 'netflix'], 17),\n",
       " (['funny', 'vlog', 'daily', 'british', 'puppy', 'zoella'], 17),\n",
       " (['funny', 'comedy', 'lol'], 17),\n",
       " (['fenty beauty', 'rihanna'], 17),\n",
       " (['football', 'sp:ty=high', 'sp:vl=en-us'], 17),\n",
       " (['vlog', 'couple'], 17),\n",
       " (['vlog', 'daily vlog'], 17),\n",
       " (['to', 'how'], 17),\n",
       " (['football', 'sp:vl=en-us', 'sp:st=football'], 17),\n",
       " (['funny', 'comedy', 'sketch comedy'], 17),\n",
       " (['soccer', 'goal'], 17),\n",
       " (['comedy', 'stand-up'], 17),\n",
       " (['ellen',\n",
       "   'the ellen show',\n",
       "   'ellen degeneres',\n",
       "   'degeneres',\n",
       "   'ellen fans',\n",
       "   'ellentube',\n",
       "   'ellen tickets'],\n",
       "  17),\n",
       " (['interview', 'news'], 16),\n",
       " (['makeup', 'beauty', 'tutorial', '2017', 'review'], 16),\n",
       " (['2017', 'beauty', 'makeup', 'vlog', 'fashion'], 16),\n",
       " (['funny', '2017', 'vlog', 'new'], 16),\n",
       " (['funny', 'vlog', 'tutorial', 'how to', 'diy'], 16),\n",
       " (['diy', 'makeup', 'halloween'], 16),\n",
       " (['funny', 'youtube'], 16),\n",
       " (['funny', '2017', 'highlight', 'football', 'highlights', 'sports', 'games'],\n",
       "  16),\n",
       " (['vlog', 'food', 'lifestyle'], 16),\n",
       " (['vlog', 'vlogging', 'makeup', 'beauty', 'vlogger'], 16),\n",
       " (['trailer', 'official'], 16),\n",
       " (['music', 'new york'], 16),\n",
       " (['makeup', 'fenty beauty'], 16),\n",
       " (['apple', 'iphone 8', 'iphone x'], 16),\n",
       " (['games',\n",
       "   '2017',\n",
       "   'highlights',\n",
       "   'highlight',\n",
       "   'game',\n",
       "   'football',\n",
       "   'sports',\n",
       "   'nfl',\n",
       "   'action',\n",
       "   'season',\n",
       "   'sport',\n",
       "   'play'],\n",
       "  16),\n",
       " (['family', 'dad', 'mom'], 16),\n",
       " (['makeup', 'get ready with me'], 16),\n",
       " (['food', 'recipe', 'kitchen', 'cook'], 16),\n",
       " (['football',\n",
       "   'nfl',\n",
       "   'amazing',\n",
       "   '2017',\n",
       "   'highlights',\n",
       "   'highlight',\n",
       "   'sports',\n",
       "   'games',\n",
       "   'game',\n",
       "   'season',\n",
       "   'sport',\n",
       "   'play',\n",
       "   'afc',\n",
       "   'plays'],\n",
       "  16),\n",
       " (['iphone 8', 'iphone x', 'iphone 8 plus'], 16),\n",
       " (['comedy', 'funny', 'promo'], 16),\n",
       " (['2017', 'run'], 16),\n",
       " (['highlight',\n",
       "   'nfl',\n",
       "   'touchdown',\n",
       "   'football',\n",
       "   'amazing',\n",
       "   'plays',\n",
       "   '2017',\n",
       "   'highlights',\n",
       "   'sports',\n",
       "   'season',\n",
       "   'sport',\n",
       "   'play',\n",
       "   'afc',\n",
       "   'american football',\n",
       "   'defense',\n",
       "   'catch'],\n",
       "  16),\n",
       " (['amazing', 'huge'], 16),\n",
       " (['funny', 'zoella', 'zoe', 'sugg'], 16),\n",
       " (['lelepons',\n",
       "   'shots',\n",
       "   'marshemllo',\n",
       "   'alesso',\n",
       "   'marshmello',\n",
       "   'shotsstudios',\n",
       "   'anwar',\n",
       "   'hannahstocking',\n",
       "   'rudymancuso',\n",
       "   'inannasarkis',\n",
       "   'inanna'],\n",
       "  16),\n",
       " (['2017',\n",
       "   'football',\n",
       "   'highlights',\n",
       "   'highlight',\n",
       "   'sports',\n",
       "   'nfl',\n",
       "   'season',\n",
       "   'sport',\n",
       "   'play',\n",
       "   'afc',\n",
       "   'plays',\n",
       "   'american football',\n",
       "   'touchdown',\n",
       "   'defense',\n",
       "   'catch',\n",
       "   'nfc',\n",
       "   'offense'],\n",
       "  16),\n",
       " (['2017', 'highlights', 'highlight', 'game', 'play', 'recap'], 16),\n",
       " (['wrestle', 'wrestling'], 16),\n",
       " (['wrestling', 'wwe'], 16),\n",
       " (['diy', 'do it yourself'], 16),\n",
       " (['refinery29', 'refinery29 video', 'r29 video', 'refinery 29', 'r29'], 16),\n",
       " (['funny',\n",
       "   'comedy',\n",
       "   'humor',\n",
       "   'celebrity',\n",
       "   'celebrities',\n",
       "   'funny video',\n",
       "   'hollywood',\n",
       "   'comedian',\n",
       "   'late night',\n",
       "   'jokes',\n",
       "   'famous',\n",
       "   'joke',\n",
       "   'cbs',\n",
       "   'celeb',\n",
       "   'funny videos',\n",
       "   'stephen colbert',\n",
       "   'impressions',\n",
       "   'monologue',\n",
       "   'james corden',\n",
       "   'colbert',\n",
       "   'corden',\n",
       "   'the late late show',\n",
       "   'late late show',\n",
       "   'karaoke',\n",
       "   'carpool',\n",
       "   'late night show'],\n",
       "  16)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximal_frequent_itemsets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
